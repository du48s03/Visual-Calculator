\section{Hand detection}
Because of our settings, there are only white background, shadow and the hand in a frame.
First, we detect hand using skin color. Then we detect wrist. Because there are only hand or wrist in the scene, we can get hand mask by erasing wrist region. Fig.\ref{fig:hand} shows the overview of the system. For wrist detection, we modify the method from \cite{ra11}.
All of the functions in this section is in majoraxis.py and hand\_detection.py.

\subsection{Skin color detection}
Since there are only white background, shadow and the hand in the screen, we can detect the hand with color. We use both RGB and HSV value to detect the skin.
%Because both of our team members are East Asian, we tried skin detection only for East Asian people.
In particular, we define skin color pixel as:
\begin{itemize}
  \item its Red value is larger than Blue value
  \item its Red value is larger than Green value
  \item its Value (HSV) is smaller than 73 \%
  \item its Saturation is larger than 30 \%
 \end{itemize}
Also, we ignore the pixels outside of the canvas.
\begin{landscape}
\begin{figure}[htbp]
 \centering
 \input{fig1.tex}
 \caption{Overview of hand detection}
 \label{fig:hand}
\end{figure}
\end{landscape}


\input{major.tex}
\subsection{Hand detection}
\begin{figure}
 \centering
 \begin{tabular}{cc}
  \includegraphics[width=5cm]{fig5/ex.png} &
  \includegraphics[width=5cm]{fig5/exng.png}
 \end{tabular}
 \caption{Hand image Left: original skin color image Right: rotated skin color image}
 \label{fig:handim}
\end{figure}
\begin{figure}
 \centering
 \begin{tabular}{c}
  \includegraphics[width=\hsize]{fig6/im.png} \\
  \includegraphics[width=\hsize]{fig6/hist.png}
 \end{tabular}
 \caption{Hand image Top: Hand image. Green line is wrist position and red line is b. Bottom: histogram}
 \label{fig:handim2}
\end{figure}

To classify the posture of the hand, the arm is not necessary. Thus, we would like to extract the hand region. We modified the method introduced by \cite{ra11}. The method is first to detect the skin region by color (and HSV), and then detect the wrist end. Wrist end is detected by the simple method as follows:
Fig.\ref{fig:handim} shows the image of the hand. 
First, we calculate the number of the pixels on the four borders of the bounding box of the skin region: 
up (between blue point and red point), 
down (between green point and yellow point), left (between blue point and green point), right (between red point and yellow point). 

Then we can assume the largest among these is the wrist side. This is because the hand is inside of the image, but human body itself is not. 

Then, Raheja et al. detect the wrist end using intensity histogram. Intensity histogram is the sum of the number of the pixels on the row/cols. If wrist end is up/ down, it calculate along rows. Otherwise, it calculate along columns.

Assume the wrist end is at the bottom. Let b be the skin pixel that is either on the left border or the right border of the minimum bounding box, and is nearest to the wrist end. Since b is either the leftmost or the rightmost pixel, the intensity histogram at b's row tend to be close to the maximum. On the other hand, the wrist is usually thinner than the arm and the hand, so the intensity histogram at the wrist tends to be close to the minimum. Let $y_b$ be the $y$ coordinate of $b$(or the $x$ coordinate if the wrist end is on the left or right), and $hist(x)$ be the intensity histogram at row $x$ (or the column $x$ if the the wrist end is on the left or right). \cite{ra11} found that, $hist(x_b) - hist(x)/(x_b-x)$ tends to be the maxium when $x$ is at the wrist. 

However, the wrist detection does not work well in the general case because the paper assumes that  the hand gesture is a  spray hand and so the palm is always the widest. Like Fig.\ref{fig:handim} shows, we cannot find the appropriate b because the leftmost and the rightmost points are not in the palm, but in the arm and fingertip.
This is because the arm is not pointing downward and this makes it difficult to detect the hand region as it is. 
So, we rotate the image along the major axis so that we can assume the wrist is always on the 'up' side and the most left or right part tends to be in the palm region.
In Fig.\ref{fig:handim} , the wrist can be detect by our method but not the previous one, because our method can detect the widest point as b correctly. 
We assume b is not too near to the wrist. That is, if a point is within 30 pixels from the wrist end, we use another point.
Fig.\ref{fig:handim2} shows an example of the intensity histogram. The red point in the histogram corresponds to b's coordinate. The green point in the histogram corresponds to the wrist's coordinate. The red line and the green line in the left image corresponds to b and the wrist detected.

Put together, our method is like follows.
\begin{enumerate}
  \item Find skin color area
  \item Find orientation of the skin area and rotate
  \item Assume up side is wrist
  \item Find wrist end and crop
\end{enumerate}

Even though we improved the method, in the case where the skin detection fails and the hand become smaller,  the palm can be too small to be the widest part. In that case, we simply extract 1/4 of all of the region.
\subsection{Result}
Fig.\ref{fig:hands} shows the results of the hand detection.
As we can see, the hands are correctly detected.

\begin{landscape}
\begin{figure}[htbp]
 \centering
 \input{fig4.tex}
 \caption{The results of hand detection}
 \label{fig:hands}
\end{figure}
\end{landscape}
