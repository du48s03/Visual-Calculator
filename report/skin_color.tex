\section{Hand detection}
Because of our settings, there are only white background, shadow and the hand in an image.
First, we detect hand using skin color. Then we detect wrist. Because there are only hand or wrist in the scene, we can get hand mask by erasing wrist region. Fig.\ref{fig:hand} shows the overview of the system. For wrist detection, we modify the method from \cite{ra11}.
All of the functions in this section is in major.py and hand\_detection.py.

\subsection{Skin color detection}
Because of our settings, there are only white background, shadow and the hand in an image.
So we detect the hand by color. We use both RGB and HSV value to detect our skin.
Because both of our team mates are East Asian, we tried skin detection only for East Asian people.
In particular, we define skin color pixel as:
\begin{itemize}
  \item its Red value is larger than Blue value
  \item its Red value is larger than Green value
  \item its Value (HSV) is smaller than 73 \%
  \item its Saturation is larger than 30 \%
 \end{itemize}
Also we mask where outside of the canvas.
\begin{landscape}
\begin{figure}[htbp]
 \centering
 \input{fig1.tex}
 \caption{Overview of hand detection}
 \label{fig:hand}
\end{figure}
\end{landscape}


\input{major.tex}
\subsection{Hand detection}
\begin{figure}
 \centering
 \includegraphics[width=5cm]{fig5/ex.png}
 \caption{Hand image}
 \label{fig:handim}
\end{figure}
Then we have to extract only hand region. If there are long arms, we may not classify the gesture correctly. We modified the method introduced by \cite{ra11}. The method is first detect the skin region by color (HSV), and then detect the wrist end. Wrist end is detected by the simple method as follows:
Fig.\ref{fig:handim} shows the image of the hand. 
First, we calculate the number of the pixels on boundaries, 
up (between blue point and red point), 
down (between green point and yellow point), left (between blue point and green point), right (between red point and yellow point). 
We can assume the most largest among up, down, left and right is the wrist side. This is because the author of \cite{ra11} and we assume hand is inside of the image, but human itself is not. 
Then, they detect the wrist end using intensity histogram. Intensity histogram is the sum of the number of the pixels on the row/cols. If wrist is up/ down, it calculate along rows. Otherwise, it calculate along columns.
Assume the wrist is down. Let p be a point which is either on a left or right boundaries and the nearest from the down boundary. The author of \cite{ra11} found that the slope on the historgam between b and the wrist end is highest among the slopes between b and other points which is nearer to down than b.
\par
However, the wrist detection does not work well because the paper assumes the hand gesture as spray hand and so the palm is always the widest. Like Fig.\ref{fig:handim}, we cannot find appropriate b because the most left or right points are not palm, but finger and wrist.
This is because palms are not fully opened so it is difficult to detect hand region as it is. 
So we rotate the image along the axis so that we can assume the wrist is always 'up' side and the most left or right part tend to be the palm region.
Fig.\ref{fig:handex}  can detect wrist by our method but not the proposed method. In this case, the proposed method detects the wrist side correctly, but it will calculate slope with either
wrist (blue dot) or fingertip (near yellow dot). Then proposed method does not work.
Our method is as follows.
\begin{enumerate}
  \item Find skin color area
  \item Find orientation of the skin area and rotate
  \item Assume up side is wrist
  \item Find wrist end and crop
\end{enumerate}
Even though we improve the method, in case the skin detection fails and the hand become smaller of the palm is too small to be a widest length, in that case, we simply extract 1/4 of the all of the region.
\subsection{Result}
Fig.\ref{fig:hands} shows the results of the hand detection.
As we can see, the hands are correctly detected.

\begin{landscape}
\begin{figure}[htbp]
 \centering
 \input{fig4.tex}
 \caption{The results of hand detection}
 \label{fig:hands}
\end{figure}
\end{landscape}
