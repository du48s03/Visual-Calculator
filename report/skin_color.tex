h\section{Hand detection}
Because of our settings, there are only white background, shadow and the hand in an image.
First, we detect hand using skin color. Then we detect wrist. Because there are only hand or wrist in the scene, we can get hand mask by erasing wrist region. Fig.\ref{fig:hand} shows the overview of the system. For wrist detection, we modify the method from \cite{ra11}.
All of the functions in this section is in major.py and hand\_detection.py.
\subsection{Skin color detection}
Because of our settings, there are only white background, shadow and the hand in an image.
So we detect the hand by color. We use both RGB and HSV value to detect our skin.
Because both of our team mates are East Asian, we tried skin detection only for East Asian people.
In particular, we define skin color pixel as:
\begin{itemize}
  \item its Red value is larger than Blue value
  \item its Red value is larger than Green value
  \item its Value (HSV) is smaller than 73 \%
  \item its Saturation is larger than 30 \%
 \end{itemize}
Also we mask where outside of the canvas.
\subsection{Hand detection}
Then we have to extract only hand region. If there are long arms, we may not classify the gesture correctly. We modified the method introduced by \cite{ra11}. The method is first detect the skin region by color (HSV), and then detect the wrist end. Wrist end is detected by the simple method as follows:
Fig.\ref{fig:handim} shows the image of the hand. 
However, the wrist detection does not work well because the paper assumes the hand gesture as spray hand and so the palm is always the widest. 
In our case, palms are not fully opened so it is difficult to detect hand region as it is. 
So we rotate the image along the axis so that we can know the side of the wrist. 
Fig.\ref{fig:handex} shows the example of the image which can detect wrist by our method but not the proposed method.
Even though we improve the method, sometimes the skin detection fails and the hand become smaller of the palm is too small to be a widest length, in that case, we simply extract 2/3 of the all of the region.
\input{major.tex}
\subsection{Result}
Fig.\ref{fig:hands} shows the results of the hand detection.
As we can see, the hands are correctly detected.

\begin{landscape}
\begin{figure}[htbp]
 \centering
 \input{fig1.tex}
 \caption{Overview of hand detection}
 \label{fig:hand}
\end{figure}
\end{landscape}

\begin{landscape}
\begin{figure}[htbp]
 \centering
 \input{fig4.tex}
 \caption{The results of hand detection}
 \label{fig:hands}
\end{figure}
\end{landscape}
