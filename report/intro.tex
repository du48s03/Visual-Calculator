\section{Introduction}
\subsection{Purpose of this project}
    In this project, we implemented a system that allows the user to paint on the screen using intuitive gestures instead of the mouse. 
    Instead of using any specific draw pad or other device, we will implement the system using a simple white paper, a web cam, and a light source. 
    Without any tactile input, we are going to rely on visual inputs to determine the gesture and the position of user's hand in real-time. 
    The challenging part about this project is how to define the natural gestures that human use to indicate the drawing on a  blank paper, and how to recognize them using pure visual signal processing. Because the system only rely on the visual input, this project is perfectly suitable as an example of a visual interface. 
\subsection{Previous work}
    EnhancedDesk\cite{a} is a two handed drawing system using infrared camera. Left hand and right hand have the different role.  Isard, Michael, and John MacCormick implemented a vision based drawing package to demonstrate the hand tracking method\cite{b}.
\subsection{Program features}
The user will be given a device that consists of a white paper, a webcam that looks down from above, 
and a light source that projects light onto the paper from a non-vertical angle.
The distance between the webcam and the paper, the paper and the light source, and the angle of the light source are all fixed. On the bottom of the paper are some color blocks which represent a palette. The user can simply touch the color blocks to choose the color he or she wants to use. In the mean time there will be a program on the computer screen which shows the canvas on which the user draws. 
To draw a picture, the user can use the most intuitive gesture -- a pointing finger. 
Touching the paper with the index finger means to draw, while moving the finger without touching the paper means to move the cursor without drawing. 
This gesture, when the user touches the palette instead of the empty area, means to select the color  instead of drawing. 
For convenience, we will also define an erase gesture, which is a palm facing downwards with the four fingers stretching straight. This gesture is easy to use, and suitable for the semantic of erasing, because it is the movement one would use to wipe something away from a surface.
\subsection{Domain engineering}
Fig.\ref{fig:1} shows the setting of our device. The height from the camera to the paper canvas is 54 cm. The camera looks downward so that we can easily convert the coordinate from the input to the output. The canvas, which is the area on which the user can draw, is 19cm by 14cm. We set the  background to white in order to detect the hand easily. The webcam model we use is logicool carl zeiss tessar. The system is implemented in python 2.7, and tested on a Windows 8 PC. As the light source, we use handy light. 
\begin{figure}
  \centering
 \input{device.tex}
 \caption{The input device}
 \label{fig:1}
\end{figure}
%\subsection{Division}
%Angus Ding (ad3180) implemented and wrote a report about posture detection, shadow detection and GUI part.
%Ayaka Kume (ak3682) implemented and wrote a report about hand detection, fingertip detection and evaluation part.
%We wrote introduction and discussion together.
\clearpage
\clearpage
